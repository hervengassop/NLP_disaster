{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import random as rd\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.util import minibatch, compounding\n",
    "from nltk.stem.porter import *  \n",
    "\n",
    "import re\n",
    "import urllib.request\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.options.display.max_columns = None\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "from spacy import displacy\n",
    "import df_helper as dfh\n",
    "\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, validation_curve\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, fbeta_score, classification_report, confusion_matrix\n",
    "\n",
    "import sklearn.metrics as met\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix, fbeta_score, make_scorer, average_precision_score, auc, \\\n",
    "    accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, classification_report, \\\n",
    "    brier_score_loss, roc_auc_score\n",
    "\n",
    "from scipy.stats import randint as sp_randint , uniform\n",
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sentence(bow, message):\n",
    "    # for eli5\n",
    "    \n",
    "    print(\"original: \",message)\n",
    "    \n",
    "    words=np.array(bow.get_feature_names())\n",
    "    TR=bow.transform([ message ])\n",
    "    g,ind=TR.nonzero()\n",
    "    transformed=\",\".join(words[ind]) \n",
    "    print(\"transformed: \",transformed)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "def explain_message(pos,fn_messages,pipe,dataset,top=10):\n",
    "    \"\"\"\n",
    "    explain_message(pos,X_test[y_fn],pipe,bow1k_bal)\n",
    "    \"\"\"\n",
    "    \n",
    "    message=fn_messages.loc[pos]\n",
    "    transform_sentence(pipe.steps[0][1],message)\n",
    "\n",
    "    print('Predicted class:', pipe.predict([message ])[0] )\n",
    "    display(eli5.show_prediction(pipe.steps[2][1],   dataset['Xtest'][pos,:] , target_names=[0,1],\n",
    "                         feature_names= pipe.steps[0][1].get_feature_names(),top=top) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('disaster_response_messages_training.csv')\n",
    "df=df.drop(columns=['original','split'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds]",
   "language": "python",
   "name": "conda-env-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
