{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import random as rd\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.util import minibatch, compounding\n",
    "from nltk.stem.porter import *  \n",
    "\n",
    "import re\n",
    "import urllib.request\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.options.display.max_columns = None\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "from spacy import displacy\n",
    "import df_helper as dfh\n",
    "import nlp_support as ns\n",
    "\n",
    "\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "import importlib\n",
    "import pickle\n",
    "from sklearn.feature_selection import SelectKBest, chi2,  RFE, RFECV, SelectFpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dfh)\n",
    "importlib.reload(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, validation_curve\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, fbeta_score, classification_report, confusion_matrix\n",
    "\n",
    "import sklearn.metrics as met\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix, fbeta_score, make_scorer, average_precision_score, auc, \\\n",
    "    accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, classification_report, \\\n",
    "    brier_score_loss, roc_auc_score\n",
    "\n",
    "from scipy.stats import randint as sp_randint , uniform\n",
    "import eli5\n",
    "\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "under_false_2500_nwords_100_mindf_1\n",
      "Original n_true, n_false: 2329 18717\n",
      "Resampled n_true, n_false: 2329 2500\n",
      "Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\ds\\lib\\timeit.py:206: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  t = self.timeit(number)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "under_false_2500_nwords_100_mindf_1\n",
      "Original n_true, n_false: 2329 18717\n",
      "Resampled n_true, n_false: 2329 2500\n"
     ]
    }
   ],
   "source": [
    "%%timeit -N 1\n",
    "\n",
    "if 1:   \n",
    "    \n",
    "    X_train,Y_train,X_test, Y_test,X_valid, Y_valid= ns.load_data()\n",
    "    n_false_sample= 2500\n",
    "    n_features=100\n",
    "\n",
    "    DOE='under_false_%s_nwords_%s_mindf_1' % (n_false_sample,n_features)\n",
    "    print(DOE)\n",
    "\n",
    "    data_set, bow_bal, tfidf = ns.train_bow(X_train,Y_train, X_test,Y_test,n_false_sample ,  max_df=0.9,min_df=1, max_features=n_features )\n",
    "\n",
    "    with open('%s_data.pkl' % DOE, 'wb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(data_set, f)\n",
    "        \n",
    "        from joblib import dump, load\n",
    "        dump(tfidf, '%s_tfidf.joblib' % DOE)\n",
    "        dump(bow_bal, '%s_bal_cv.joblib' % DOE)\n",
    "        \n",
    "    print('Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DOE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-526ba73e83e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s_data.pkl'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mDOE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Pickle the 'data' dictionary using the highest protocol available.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DOE' is not defined"
     ]
    }
   ],
   "source": [
    "with open('%s_data.pkl' % DOE, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(data_set, f)\n",
    "\n",
    "    from joblib import dump, load\n",
    "    dump(tfidf, '%s_tfidf.joblib' % DOE)\n",
    "    dump(bow_bal, '%s_bal_cv.joblib' % DOE)\n",
    "\n",
    "print('Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "if 1:\n",
    "\n",
    "    X_train,Y_train,X_test, Y_test,X_valid, Y_valid= ns.load_data()\n",
    "    n_false_sample= None\n",
    "    n_features=5000\n",
    "\n",
    "    DOE='fs_false_all_nwords_%s_mindf_1' % (n_false_sample,n_features)\n",
    "    print(DOE)\n",
    "\n",
    "    data_set2, bow_bal2, tfidf2 = ns.train_bow(X_train,Y_train, X_test,Y_test,n_false_sample ,  max_df=0.9,min_df=1, max_features=n_features )\n",
    "\n",
    "    with open('%s_data.pkl' % DOE, 'wb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(data_set2, f)\n",
    "        \n",
    "        from joblib import dump, load\n",
    "        dump(tfidf2, '%s_tfidf.joblib' % DOE)\n",
    "        dump(bow_bal2, '%s_bal_cv.joblib' % DOE)\n",
    "        \n",
    "    print('Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds]",
   "language": "python",
   "name": "conda-env-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
